# Does DL really improve standard CF strategies?
This repository contains the code of my MSc Thesis in Artifical Intelligence at Tilburg University. The goal of the project was to test whether DL models are to be preferred over standard techniques to develop RSs.
The thesis was graded 7.5/10 and it was awarded with **distinction**

## Abstract
Given the positive results of applying Deep Learning (DL) to fields like Computer Vision and Speech Recognition, in recent years, the Recommender Systems (RSs) community has decided to apply DL components to improve the overall performance of RSs models. Among the most recent supporters of DL techniques there are Howard and Gugger (2020) and Ahamed and Afroge (2019), who applied He et al. (2017)’s Neural Collaborative Filtering (NCF) framework to ex- plicit feedback. These studies support the idea that applying neural networks to standard Matrix Factorization (MF) techniques yields better results than using standard techniques. Inspired by Dacrema, Cremonesi, and Jannach (2019), who proved that standard techniques can beat DL- enhanced models, if an accurate experiment is conducted, this work asks the following question: "can a properly tuned standard MF technique outperform recent DL-enhanced RSs based on explicit feedback?" This study tries to overcome some of the shortcomings of Howard and Gugger (2020) and Ahamed and Afroge (2019)’s models, by using a more challenging dataset (the Netflix dataset), a strong baseline for the given dataset (ImprovedRSVD) and by tuning the models with different configurations of hyper-parameters in two consecutive experiments. The results showed that the baseline reached a test RMSE of 0.98 while the best DL model reached a test RMSE of 1.00, therefore proving that a simple standard technique can beat DL enhanced models by performing consistently better than them, even after two successive tuning stages.
